{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CZFfMovg6D4p"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvt-OHa4y6JC",
        "outputId": "4643b7b9-4f50-4562-cda7-317a2d67786c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 17010 images belonging to 3 classes.\n",
            "Found 4254 images belonging to 3 classes.\n",
            "Epoch 1/30\n",
            "532/532 [==============================] - 91s 169ms/step - loss: 1.0421 - accuracy: 0.4556 - val_loss: 0.9156 - val_accuracy: 0.5827\n",
            "Epoch 2/30\n",
            "532/532 [==============================] - 88s 166ms/step - loss: 0.8993 - accuracy: 0.5680 - val_loss: 0.8187 - val_accuracy: 0.6093\n",
            "Epoch 3/30\n",
            "532/532 [==============================] - 87s 163ms/step - loss: 0.8323 - accuracy: 0.6078 - val_loss: 0.7909 - val_accuracy: 0.6302\n",
            "Epoch 4/30\n",
            "532/532 [==============================] - 86s 162ms/step - loss: 0.7874 - accuracy: 0.6364 - val_loss: 0.7700 - val_accuracy: 0.6436\n",
            "Epoch 5/30\n",
            "532/532 [==============================] - 86s 161ms/step - loss: 0.7513 - accuracy: 0.6496 - val_loss: 0.7677 - val_accuracy: 0.6465\n",
            "Epoch 6/30\n",
            "532/532 [==============================] - 86s 162ms/step - loss: 0.7175 - accuracy: 0.6711 - val_loss: 0.7475 - val_accuracy: 0.6655\n",
            "Epoch 7/30\n",
            "532/532 [==============================] - 88s 165ms/step - loss: 0.6795 - accuracy: 0.6891 - val_loss: 0.7464 - val_accuracy: 0.6624\n",
            "Epoch 8/30\n",
            "532/532 [==============================] - 87s 163ms/step - loss: 0.6464 - accuracy: 0.7104 - val_loss: 0.7395 - val_accuracy: 0.6737\n",
            "Epoch 9/30\n",
            "532/532 [==============================] - 101s 190ms/step - loss: 0.6094 - accuracy: 0.7295 - val_loss: 0.7746 - val_accuracy: 0.6664\n",
            "Epoch 10/30\n",
            "532/532 [==============================] - 86s 161ms/step - loss: 0.5781 - accuracy: 0.7437 - val_loss: 0.7604 - val_accuracy: 0.6714\n",
            "Epoch 11/30\n",
            "532/532 [==============================] - 84s 159ms/step - loss: 0.5427 - accuracy: 0.7606 - val_loss: 0.8054 - val_accuracy: 0.6627\n",
            "Epoch 12/30\n",
            "532/532 [==============================] - 87s 163ms/step - loss: 0.5069 - accuracy: 0.7767 - val_loss: 0.8197 - val_accuracy: 0.6721\n",
            "Epoch 13/30\n",
            "532/532 [==============================] - 85s 159ms/step - loss: 0.4851 - accuracy: 0.7875 - val_loss: 0.8388 - val_accuracy: 0.6674\n",
            "Epoch 14/30\n",
            "532/532 [==============================] - 86s 161ms/step - loss: 0.4517 - accuracy: 0.8025 - val_loss: 0.8849 - val_accuracy: 0.6732\n",
            "Epoch 15/30\n",
            "532/532 [==============================] - 84s 157ms/step - loss: 0.4253 - accuracy: 0.8125 - val_loss: 0.9095 - val_accuracy: 0.6754\n",
            "Epoch 16/30\n",
            "532/532 [==============================] - 83s 157ms/step - loss: 0.4005 - accuracy: 0.8243 - val_loss: 0.9567 - val_accuracy: 0.6671\n",
            "Epoch 17/30\n",
            "532/532 [==============================] - 84s 157ms/step - loss: 0.3843 - accuracy: 0.8316 - val_loss: 0.9523 - val_accuracy: 0.6784\n",
            "Epoch 18/30\n",
            "532/532 [==============================] - 84s 158ms/step - loss: 0.3610 - accuracy: 0.8422 - val_loss: 1.0298 - val_accuracy: 0.6838\n",
            "Epoch 19/30\n",
            "532/532 [==============================] - 82s 155ms/step - loss: 0.3376 - accuracy: 0.8510 - val_loss: 1.0366 - val_accuracy: 0.6794\n",
            "Epoch 20/30\n",
            "532/532 [==============================] - 84s 158ms/step - loss: 0.3292 - accuracy: 0.8576 - val_loss: 1.0514 - val_accuracy: 0.6775\n",
            "Epoch 21/30\n",
            "532/532 [==============================] - 84s 158ms/step - loss: 0.3111 - accuracy: 0.8647 - val_loss: 1.1103 - val_accuracy: 0.6725\n",
            "Epoch 22/30\n",
            "532/532 [==============================] - 86s 161ms/step - loss: 0.2970 - accuracy: 0.8731 - val_loss: 1.1596 - val_accuracy: 0.6742\n",
            "Epoch 23/30\n",
            "532/532 [==============================] - 84s 158ms/step - loss: 0.2817 - accuracy: 0.8778 - val_loss: 1.2659 - val_accuracy: 0.6761\n",
            "Epoch 24/30\n",
            "532/532 [==============================] - 84s 158ms/step - loss: 0.2845 - accuracy: 0.8768 - val_loss: 1.2274 - val_accuracy: 0.6725\n",
            "Epoch 25/30\n",
            "532/532 [==============================] - 84s 158ms/step - loss: 0.2739 - accuracy: 0.8842 - val_loss: 1.2869 - val_accuracy: 0.6775\n",
            "Epoch 26/30\n",
            "532/532 [==============================] - 85s 159ms/step - loss: 0.2585 - accuracy: 0.8873 - val_loss: 1.3874 - val_accuracy: 0.6768\n",
            "Epoch 27/30\n",
            "532/532 [==============================] - 84s 158ms/step - loss: 0.2531 - accuracy: 0.8894 - val_loss: 1.3109 - val_accuracy: 0.6688\n",
            "Epoch 28/30\n",
            "532/532 [==============================] - 85s 159ms/step - loss: 0.2459 - accuracy: 0.8958 - val_loss: 1.2932 - val_accuracy: 0.6732\n",
            "Epoch 29/30\n",
            "532/532 [==============================] - 86s 162ms/step - loss: 0.2441 - accuracy: 0.8930 - val_loss: 1.4654 - val_accuracy: 0.6690\n",
            "Epoch 30/30\n",
            "532/532 [==============================] - 83s 157ms/step - loss: 0.2412 - accuracy: 0.8969 - val_loss: 1.3313 - val_accuracy: 0.6707\n",
            "Training complete and model saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\miniconda\\envs\\myenv\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Step 1: Data Loading\n",
        "# Assuming your data is organized like:\n",
        "# - dataset/\n",
        "#     - train/\n",
        "#         - happy/\n",
        "#         - sad/\n",
        "#         - angry/\n",
        "#     - test/\n",
        "#         - happy/\n",
        "#         - sad/\n",
        "#         - angry/\n",
        "\n",
        "train_dir = r'D:\\DESKTOP\\AI proj\\archive_sentiments\\train'\n",
        "test_dir = r\"D:\\DESKTOP\\AI proj\\archive_sentiments\\test\"\n",
        "\n",
        "# Step 2: Data Preprocessing\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(64, 64),    # You can change size\n",
        "    batch_size=32,\n",
        "    class_mode='categorical' # If more than 2 classes\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Step 3: CNN Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(train_generator.num_classes, activation='softmax')  # Output layer\n",
        "])\n",
        "\n",
        "# Step 4: Compile Model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Step 5: Train Model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=test_generator\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: D:\\DESKTOP\\AI proj\\finalage_sentimentmodel\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: D:\\DESKTOP\\AI proj\\finalage_sentimentmodel\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training complete and model saved!\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Save Model\n",
        "model.save(r'D:\\DESKTOP\\AI proj\\finalage_sentimentmodel')\n",
        "\n",
        "print(\"Training complete and model saved!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
