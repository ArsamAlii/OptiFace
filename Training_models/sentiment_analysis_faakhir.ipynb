{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZFfMovg6D4p"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkpqG7U06ZXp",
        "outputId": "497425e5-6f39-4806-f44c-2fa146d169c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unzipped successfully!\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "# Assuming the uploaded file name\n",
        "zip_file_path = 'a.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/datalab/')  # You can change the path if needed\n",
        "\n",
        "print(\"Unzipped successfully!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvt-OHa4y6JC",
        "outputId": "83fba9d5-07a9-41ca-c7a6-aa33dce959f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 17010 images belonging to 3 classes.\n",
            "Found 4254 images belonging to 3 classes.\n",
            "Epoch 1/15\n",
            "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 239ms/step - accuracy: 0.4598 - loss: 1.0349 - val_accuracy: 0.5936 - val_loss: 0.8571\n",
            "Epoch 2/15\n",
            "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 241ms/step - accuracy: 0.6213 - loss: 0.8049 - val_accuracy: 0.6580 - val_loss: 0.7453\n",
            "Epoch 3/15\n",
            "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 238ms/step - accuracy: 0.6807 - loss: 0.7052 - val_accuracy: 0.6761 - val_loss: 0.7138\n",
            "Epoch 4/15\n",
            "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 243ms/step - accuracy: 0.7048 - loss: 0.6638 - val_accuracy: 0.6881 - val_loss: 0.6932\n",
            "Epoch 5/15\n",
            "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 238ms/step - accuracy: 0.7307 - loss: 0.6079 - val_accuracy: 0.7040 - val_loss: 0.6704\n",
            "Epoch 6/15\n",
            "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 242ms/step - accuracy: 0.7520 - loss: 0.5712 - val_accuracy: 0.6970 - val_loss: 0.6789\n",
            "Epoch 7/15\n",
            "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 237ms/step - accuracy: 0.7753 - loss: 0.5209 - val_accuracy: 0.6991 - val_loss: 0.6868\n",
            "Epoch 8/15\n",
            "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 241ms/step - accuracy: 0.8019 - loss: 0.4665 - val_accuracy: 0.7069 - val_loss: 0.7097\n",
            "Epoch 9/15\n",
            "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 239ms/step - accuracy: 0.8375 - loss: 0.4067 - val_accuracy: 0.6946 - val_loss: 0.7385\n",
            "Epoch 10/15\n",
            "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 241ms/step - accuracy: 0.8648 - loss: 0.3402 - val_accuracy: 0.7015 - val_loss: 0.7824\n",
            "Epoch 11/15\n",
            "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 239ms/step - accuracy: 0.8902 - loss: 0.2861 - val_accuracy: 0.7008 - val_loss: 0.9190\n",
            "Epoch 12/15\n",
            "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 244ms/step - accuracy: 0.9174 - loss: 0.2240 - val_accuracy: 0.6921 - val_loss: 0.9244\n",
            "Epoch 13/15\n",
            "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 237ms/step - accuracy: 0.9387 - loss: 0.1701 - val_accuracy: 0.7132 - val_loss: 1.0435\n",
            "Epoch 14/15\n",
            "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 239ms/step - accuracy: 0.9516 - loss: 0.1399 - val_accuracy: 0.7033 - val_loss: 1.2072\n",
            "Epoch 15/15\n",
            "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 242ms/step - accuracy: 0.9633 - loss: 0.1037 - val_accuracy: 0.7040 - val_loss: 1.3190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete and model saved!\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "\n",
        "train_dir = '/datalab/train'\n",
        "test_dir = '/datalab/test'\n",
        "\n",
        "# Data Preprocessing\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(64, 64),    # can change size\n",
        "    batch_size=32,\n",
        "    class_mode='categorical' # If more than 2 classes\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# CNN Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(train_generator.num_classes, activation='softmax')  # Output layer\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train Model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=15,\n",
        "    validation_data=test_generator\n",
        ")\n",
        "\n",
        "\n",
        "model.save('emotion_analysis.h5')\n",
        "\n",
        "print(\"Training complete and model saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnR0Br5H65c_",
        "outputId": "8bc6caaa-8442-481f-a2a3-14bee618f822"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "model_path = '/content/emotion_analysis.h5'\n",
        "\n",
        "# Load the model\n",
        "model = keras.models.load_model(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTEwrshQu7Ty",
        "outputId": "bcadcc77-fcfc-42dc-a7f1-79213ba04e73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'happy': 0, 'neutral': 1, 'sad': 2}\n"
          ]
        }
      ],
      "source": [
        "# Print the class indices mapping\n",
        "print(train_generator.class_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vomuhk1_8FKf",
        "outputId": "38b9b515-0487-4cca-f95c-0ae3770c5586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
            "Predicted Emotion: 0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "\n",
        "# Load your trained model\n",
        "model = load_model('emotion_analysis.h5')\n",
        "\n",
        "# Load an image you want to predict\n",
        "img = image.load_img('images.jpg', target_size=(64, 64))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = img_array / 255.0     # Same scaling as training!\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Model expects batch dimension\n",
        "\n",
        "# Predict\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "# Get class indices\n",
        "class_indices =  train_generator.class_indices  # {'happy': 0, 'neutral': 1, 'sad': 2}\n",
        "labels = list(class_indices.values())             # ['happy', 'neutral', 'sad']\n",
        "\n",
        "# Get predicted class\n",
        "predicted_class_index = np.argmax(prediction)   # argmax\n",
        "predicted_label = labels[predicted_class_index]\n",
        "\n",
        "print(f\"Predicted Emotion: {predicted_label}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
